<!DOCTYPE html>
<html lang="en-US">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Caltech AI Alignment Group</title>
    <meta name="description" content="Caltech AI Alignment Group">
    <link rel="icon" href="https://caltechaia.org/wp-content/uploads/2024/02/1-150x150.png" sizes="32x32">
    
    <!-- Basic CSS for layout and styling -->
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: "Fraunces", serif;
            font-size: 20px;
            line-height: 1.7;
            color: #1F2127;
            background-color: #ECE6DC;
        }
        
        .container {
            max-width: 1140px;
            margin: 0 auto;
            padding: 0 24px;
        }
        
        header {
            border-bottom: 2px solid;
            padding: 24px;
        }
        
        .header-content {
            display: flex;
            justify-content: space-between;
            align-items: center;
            flex-wrap: wrap;
        }
        
        h1 {
            color: #ff6c0c;
            font-size: 32px;
            font-weight: 400;
        }
        
        nav ul {
            display: flex;
            list-style: none;
            gap: 20px;
        }
        
        nav a {
            text-decoration: none;
            color: #1F2127;
        }
        
        nav a:hover {
            color: #ff6c0c;
        }
        
        main {
            padding: 64px 0;
        }
        
        .hero {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 40px;
            align-items: center;
            margin-bottom: 64px;
        }
        
        .hero h1 {
            color: #ff6c0c;
            font-size: 64px;
            font-weight: 300;
            line-height: 1.25;
        }
        
        .hero p {
            margin: 24px 0;
        }
        
        .cta-button {
            display: inline-block;
            background-color: #ff6c0c;
            color: white;
            padding: 16px 32px;
            text-decoration: none;
            font-weight: 600;
            margin: 24px 0;
        }
        
        .cta-button:hover {
            background-color: #e55a00;
        }
        
        .hero img {
            width: 100%;
            height: auto;
        }
        
        .content-section {
            margin: 64px 0;
        }
        
        .two-column {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 40px;
        }
        
        .content-section h3 {
            font-size: 28px;
            font-weight: 400;
            margin-bottom: 24px;
        }
        
        .content-section ol {
            padding-left: 20px;
        }
        
        .content-section li {
            margin-bottom: 16px;
        }
        
        .content-section a {
            color: #ff6c0c;
        }
        
        .highlight-section {
            background-color: #1F2125;
            color: #FFFFFF;
            padding: 32px 24px;
            margin: 64px 0;
        }
        
        .highlight-content {
            display: flex;
            justify-content: space-between;
            align-items: center;
            max-width: 1140px;
            margin: 0 auto;
        }
        
        .outline-button {
            border: 2px solid #FFFFFF;
            background: transparent;
            color: #FFFFFF;
            padding: 16px 32px;
            text-decoration: none;
            display: inline-block;
        }
        
        .outline-button:hover {
            background-color: #FFFFFF;
            color: #1F2125;
        }
        
        footer {
            background-color: #1F2125;
            color: #FFFFFF;
            padding: 24px;
            margin-top: 64px;
        }
        
        .footer-content {
            display: flex;
            justify-content: space-between;
            align-items: center;
            max-width: 1140px;
            margin: 0 auto;
        }
        
        @media (max-width: 768px) {
            .hero,
            .two-column {
                grid-template-columns: 1fr;
            }
            
            .header-content,
            .highlight-content,
            .footer-content {
                flex-direction: column;
                gap: 20px;
                text-align: center;
            }
            
            nav ul {
                flex-direction: column;
                align-items: center;
            }
            
            .hero h1 {
                font-size: 48px;
            }
        }
    </style>
</head>
<body>
    <header>
        <div class="container">
            <div class="header-content">
                <h1>Caltech AI Alignment</h1>
                <nav>
                    <ul>
                        <li><a href="#what-is-alignment">What is AI Alignment?</a></li>
                        <li><a href="#not-studying-cs">Not Studying CS?</a></li>
                        <li><a href="#ml-safety">What is ML Safety?</a></li>
                    </ul>
                </nav>
            </div>
        </div>
    </header>

    <main>
        <div class="container">
            <section class="hero">
                <div>
                    <h1><strong>AI might change the world as we know it.</strong></h1>
                    <p><em>let's ensure those changes are positive</em>.</p>
                    <p><strong>Apply to our Intro to ML Safety Fellowship, <em>by Sunday, February 1st at 6:00pm PT</em> here:</strong></p>
                    <a href="https://forms.gle/UiYPUZeykner28L37" class="cta-button" target="_blank">CAIA Fellowship</a>
                </div>
                <div>
                    <img src="https://caltechaia.org/wp-content/uploads/2024/02/clarote_ai4media_labour_resources_2560x1440.png" alt="AI visualization" />
                </div>
            </section>

            <section class="content-section">
                <div class="two-column">
                    <div>
                        <h3>We think positively shaping transformative AI is worth working on because:</h3>
                        <ol>
                            <li>Experts predict that we will likely see <a href="https://aiimpacts.org/2022-expert-survey-on-progress-in-ai/" target="_blank">human-level AI within our lifetimes</a>.</li>
                            <li>Getting future AI systems to share human values looks like it could be an <a href="https://www.deepmind.com/blog/specification-gaming-the-flip-side-of-ai-ingenuity" target="_blank">extremely</a> <a href="https://www.lesswrong.com/tag/instrumental-convergence" target="_blank">difficult</a> <a href="https://www.alignmentforum.org/tag/goodhart-s-law" target="_blank">technical</a> <a href="https://www.youtube.com/watch?v=bJLcIBixGj8&feature=youtu.be" target="_blank">problem</a>.</li>
                            <li>Moreover, even with a technical solution, coordinating corporate and government actors to safely deploy these systems is itself a <a href="https://www.allandafoe.com/opportunity" target="_blank">very thorny policy issue</a>.</li>
                        </ol>
                    </div>
                    <div>
                        <h3>AI Alignment is a problem of immense stakes:</h3>
                        <ol>
                            <li>Succeeding in aligning powerful AI systems could usher in a new world of <a href="https://nickbostrom.com/fable/dragon">human flourishing</a>, a world free from poverty, oppression, and suffering.</li>
                            <li>Failure to solve this problem appears to pose a major risk of <a href="https://arxiv.org/abs/2206.13353">human extinction</a> or the <a href="https://forum.effectivealtruism.org/posts/Y3sWcbcF7np35nzgu/without-specific-countermeasures-the-easiest-path-to-1">disempowerment of humanity</a>.</li>
                            <li>Despite these stakes, this problem is extremely neglected, with only a <a href="https://80000hours.org/problem-profiles/artificial-intelligence/#neglectedness">few hundred people</a> working on it full time. That's why we need you!</li>
                        </ol>
                    </div>
                </div>
            </section>

            <section class="content-section">
                <h3 style="color: #ff6c0c;">Get involved with CAIA</h3>
                <p>We think that reducing risks from advanced artificial intelligence may be one of the most important problems of our time. We also think it's a highly interesting and exciting problem, with open opportunities for many more researchers to make progress on it.</p>
                <p>CAIA exposes undergraduate and graduate students exploring research relevant to reducing risks from advanced AI by running a quarter-long introductory fellowship group on AI safety for technical machine learning track.</p>
                <p>We are welcoming eager folks to join our leadership team! If you would like to join, fill up the interest form, and write regarding your interest to <strong>caltechaia@gmail.com</strong></p>
            </section>
        </div>

        <section class="highlight-section">
            <div class="highlight-content">
                <div>
                    <p style="font-size: 32px;">Join our Discord after filling our interest form!</p>
                </div>
                <div>
                    <a href="https://bit.ly/caiainterestformgeneral" class="outline-button" target="_blank">Interest Form → Discord</a>
                </div>
            </div>
        </section>

        <div class="container">
            <section class="content-section">
                <div class="two-column">
                    <div>
                        <img src="https://caltechaia.org/wp-content/uploads/2024/02/ai-city_2560x1440-1024x576.png" alt="AI city visualization" style="width: 100%; height: auto;" />
                        <h3><a href="#" style="color: #ff6c0c;">Why care about AI Safety?</a></h3>
                        <p>In recent years, we've seen AI exceed our expectations in a wide variety of domains — including playing Go, composing human-like text, writing code, and modeling protein folding. It may not be long until we create AI systems that are <a href="https://waitbutwhy.com/2015/01/artificial-intelligence-revolution-1.html" target="_blank">much more capable than humans</a> at solving most cognitive problems.</p>
                    </div>
                    <div>
                        <img src="https://caltechaia.org/wp-content/uploads/2024/02/jamillah-knowles_data-people_3952x2472-1024x641.jpg" alt="Data visualization with people" style="width: 100%; height: auto;" />
                        <h3><a href="#" style="color: #ff6c0c;">What does work in AI Safety look like?</a></h3>
                        <p>"AI safety" refers to efforts to prevent artificial intelligence from causing harm. Possible harms from powerful future AI systems pursuing goals in conflict with human flourishing, because such systems could pose an <a href="https://aisafety.info/?state=8503&question=What%20are%20the%20main%20sources%20of%20AI%20existential%20risk%3F" target="_blank">existential risk</a> to humanity.</p>
                    </div>
                </div>
            </section>
        </div>
    </main>

    <footer>
        <div class="footer-content">
            <div>
                <p>Caltech AI Alignment</p>
            </div>
            <div>
                <p>caltechaia@gmail.com</p>
            </div>
        </div>
    </footer>
</body>
</html>
